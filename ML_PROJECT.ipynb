{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the headers to our data for clarity\n",
    "data_file_path = 'welddb/welddb.data'\n",
    "headers_file_path = 'welddb/headers.txt'\n",
    "with open(headers_file_path, 'r') as f:\n",
    "    headers = [line.strip() for line in f]\n",
    "df = pd.read_csv(data_file_path, sep=r'\\s+', header=None, names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how many different sources we haves\n",
    "\n",
    "unique = []\n",
    "for i in df['Weld ID'].unique():\n",
    "    if i.split('/')[0] not in unique:\n",
    "        unique.append(i.split('/')[0])\n",
    "unique2 = []\n",
    "for i in unique:\n",
    "    if i.split('-')[0] not in unique2:\n",
    "        try :\n",
    "            unique2.append(i.split('-')[0].concat(i.split('-')[1]))\n",
    "        except:\n",
    "            unique2.append(i.split('-')[0])\n",
    "unique3 = []\n",
    "for i in unique2:\n",
    "    if i.split('+')[0] not in unique3:\n",
    "        unique3.append(i.split('+')[0])\n",
    "unique3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the presence of an 'N' indicates that the value was not reported in the publication. We will replace this character with a `NaN` value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 59 different sources, this justifies why we have a lot of missing values and a lot of anomalies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('N', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the variable types so we can convert them to the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that 40 columns are of type `object` (likely containing strings or improperly formatted data) and 4 columns are `float64` (numeric).\n",
    "\n",
    "We will inspect and clean the `object` columns to ensure proper numeric conversions where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the 1197th row\n",
    "df.loc[1197]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows that are expected to have numerical values may contain non-numerical ones (e.g the `'<0.002'` value assigned to the variable *Sulphur concentration (weight%)* in the 1197th row of the DataFrame).\n",
    "\n",
    "First, we will convert the rows that can be converted, and then we will handle the remaining ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the variables to numeric if possible\n",
    "def convert_to_numeric(column):\n",
    "    try:\n",
    "        return pd.to_numeric(column)\n",
    "    except ValueError:\n",
    "        return column  # If conversion fails, return the original column\n",
    "\n",
    "df = df.apply(convert_to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude:\n",
    "\n",
    "- **23 columns** are of type `float64`, indicating they have successfully been converted to numeric data types (floating-point numbers).\n",
    "- **21 columns** are still of type `object`, meaning they likely contain non-numeric data, mixed types, or have values that couldn't be converted (e.g., strings or special characters).\n",
    "\n",
    "Further cleaning may be needed for the non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only columns of type object\n",
    "object_columns = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Loop through each object column and display non-numeric values\n",
    "for column in object_columns.columns:\n",
    "    print(f\"Non-numeric values in column '{column}':\")\n",
    "    non_numeric_values = df[column][pd.to_numeric(df[column], errors='coerce').isna()].unique()\n",
    "    print(non_numeric_values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the non-numeric values in the `object` columns contain a mixture of:\n",
    "\n",
    "1. **Special characters** like `<`, `+`, `-`, and ranges (e.g., `150-200`).\n",
    "2. **Text-based values** (e.g., `'67tot33res'` or `'AC'`/`'DC'`).\n",
    "3. **Units embedded in the values** (e.g., `'158(Hv30)'` or `'459Hv10'`).\n",
    "4. **Missing values**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Special characters (e.g., `<0.002`)**:\n",
    "   - First we will replace values like `<0.002` with numeric approximations (e.g., `0.002`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({r'<': '', }, regex=True, inplace=True)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Ranges (e.g., `150-200`)**:\n",
    "   - Now, we will extract the mean of the range or split it into two columns for the lower and upper bounds.\n",
    "\n",
    "In fact, this variable, Interpass temperature (°C), describes the temperature of the material between multiple passes of the welding process. Maintaining a consistent interpass temperature is critical for ensuring the quality and mechanical properties of the weld. In some rows, the recorded value for this variable is given as a range, such as 150-200°C, rather than a single temperature.\n",
    "\n",
    "Since we need a numerical value for further analysis, we will transform this interval into its median value, which in this case is 175°C. This allows us to approximate the interpass temperature while ensuring that the data remains consistent and usable for modeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the non-numeric entries in 'Nitrogen concentration (ppm)'\n",
    "df1['Interpass temperature (deg C)_numeric'] = pd.to_numeric(df1['Interpass temperature (deg C)'], errors='coerce')\n",
    "\n",
    "# Identify rows where the conversion resulted in NaN (indicating non-numeric values)\n",
    "problematic_entries = df1[df1['Interpass temperature (deg C)_numeric'].isna() & ~df1['Interpass temperature (deg C)'].isna()]['Interpass temperature (deg C)'].unique()\n",
    "\n",
    "df1 = df1.drop(columns=['Interpass temperature (deg C)_numeric'])\n",
    "\n",
    "problematic_entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the rows with a value of '150-200' in 'Interpass temperature (deg C)'\n",
    "df[df['Interpass temperature (deg C)'] == '150-200'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Interpass temperature (deg C)'] = df['Interpass temperature (deg C)'].apply(converter)\n",
    "df['Interpass temperature (deg C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Text-based values (e.g., `'67tot33res'`)**:\n",
    "   - We will investigate further to encode them meaningfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's address the column: **'Nitrogen concentration (ppm)'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the non-numeric entries in 'Nitrogen concentration (ppm)'\n",
    "df1['Nitrogen concentration (ppm)_numeric'] = pd.to_numeric(df1['Nitrogen concentration (ppm)'], errors='coerce')\n",
    "\n",
    "# Identify rows where the conversion resulted in NaN (indicating non-numeric values)\n",
    "problematic_entries = df1[df1['Nitrogen concentration (ppm)_numeric'].isna() & ~df1['Nitrogen concentration (ppm)'].isna()]['Nitrogen concentration (ppm)'].unique()\n",
    "\n",
    "df1 = df1.drop(columns=['Nitrogen concentration (ppm)_numeric'])\n",
    "\n",
    "problematic_entries  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extensive investigation into the meaning of these values, we discovered through various articles that the notation **XtotYres** is an abbreviation for **X total** and **Y residual**. This indicates that the nitrogen concentration in the material is divided into two components: the total concentration (X) and the residual concentration (Y), which remains after some process (nd stands for non-detected).\n",
    "\n",
    "For the purpose of our analysis, we will focus on the total concentration (X), as it represents the complete amount of nitrogen present in the material before any processes or reactions occur. The residual concentration often reflects secondary or incomplete reactions and is typically less representative of the material's initial state or overall chemical composition. By considering the total concentration, we ensure that our analysis captures the full nitrogen content, which is more relevant for evaluating the material's properties and predicting weld quality.\n",
    "\n",
    "*(We have only 59 values containing residual concentrations, so we don't need to consider the residual concentration as a new independent variable.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will therefore replace the values of these cases with the total concentration (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the problematic entries to numeric\n",
    "def converter(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float(x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nitrogen concentration (ppm)'] = df['Nitrogen concentration (ppm)'].apply(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nitrogen concentration (ppm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all **'Nitrogen concentration (ppm)'** values are numerical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Embedded units (e.g., `'158(Hv30)'`)**:\n",
    "   - Now, we will investigate more on this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Hardness (kgmm-2)_numeric'] = pd.to_numeric(df1['Hardness (kgmm-2)'], errors='coerce')\n",
    "\n",
    "# Identify rows where the conversion resulted in NaN (indicating non-numeric values)\n",
    "problematic_entries = df1[df1['Hardness (kgmm-2)_numeric'].isna() & ~df1['Hardness (kgmm-2)'].isna()]['Hardness (kgmm-2)'].unique()\n",
    "\n",
    "df1 = df1.drop(columns=['Hardness (kgmm-2)_numeric'])\n",
    "\n",
    "problematic_entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove '(' and ')' from the 'Hardness (kgmm-2)' column\n",
    "df['Hardness (kgmm-2)'] = df['Hardness (kgmm-2)'].str.replace('(', '')\n",
    "df['Hardness (kgmm-2)'] = df['Hardness (kgmm-2)'].str.replace(')', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot categorical data\n",
    "df['Hardness (kgmm-2)'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of missing values\n",
    "df['Hardness (kgmm-2)'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Hardness (kgmm-2)_numeric'] = pd.to_numeric(df1['Hardness (kgmm-2)'], errors='coerce')\n",
    "\n",
    "# Identify rows where the conversion resulted in NaN (indicating non-numeric values)\n",
    "problematic_entries = df1[df1['Hardness (kgmm-2)_numeric'].isna() & ~df1['Hardness (kgmm-2)'].isna()]['Hardness (kgmm-2)'].unique()\n",
    "\n",
    "df1 = df1.drop(columns=['Hardness (kgmm-2)_numeric'])\n",
    "\n",
    "problematic_entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this column, we have two types of hardness values:\n",
    "\n",
    "1. **Numerical values**: These are already standardized, such as `257`, `153`, etc.\n",
    "2. **Mixed values**: These values are formatted as `xHVy` (e.g., `150Hv30`), where `x` is the hardness value and `y` is the load in kgf used during the test.\n",
    "\n",
    "We need to standardize all the values in this column so that they are comparable, assuming a standard load of **10 kgf**.\n",
    "\n",
    "We will use the following formula to standardize values to a common load (e.g., 10 kgf):\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "Hv_{\\text{standard}} = Hv_{\\text{measured}} \\times \\left( \\frac{L_{\\text{standard}}}{L_{\\text{measured}}} \\right)^n\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ Hv_{\\text{standard}} $ is the standardized hardness value.\n",
    "- $ Hv_{\\text{measured}} $ is the hardness value measured at a specific load.\n",
    "- $  L_{\\text{standard}} $ is the standard load we will choose (in this case, **10 kgf**).\n",
    "- $  L_{\\text{measured}} $ is the load used during the measurement (extracted from the notation `xHVy`).\n",
    "- $  n  $ is an empirical constant, typically around **0.2** for metals.\n",
    "\n",
    "\n",
    "\n",
    "For values that don't mention a load (e.g., `257`), we will assume the default load used was **10 kgf**, meaning no adjustment is necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0.2\n",
    "L_standard = 10\n",
    "\n",
    "def transformer(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if x != np.nan :\n",
    "            liste=x.split('Hv')\n",
    "            L_measured = float(liste[1])\n",
    "            HV_measured = float(liste[0])\n",
    "            return HV_measured*((L_standard/L_measured)**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hardness (kgmm-2)'] = df['Hardness (kgmm-2)'].apply(transformer)\n",
    "df['Hardness (kgmm-2)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, now the hardness column is float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Non-numeric categories (e.g., `'AC'`, `'DC'`, `'+'`, `'-'`)**:\n",
    "   - These categorical values can be encoded later (e.g., with `LabelEncoder` or `OneHotEncoder`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "df[object_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoding to ac vs dc and Electrode positive or negative\n",
    "\n",
    "df222 = pd.get_dummies(df, columns=['AC or DC', 'Electrode positive or negative'])[['AC or DC_AC',\t'AC or DC_DC', 'Electrode positive or negative_+', 'Electrode positive or negative_-',\t'Electrode positive or negative_0']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix plot \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "corr = df222.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AC or DC'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrode positive or negative'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column ac or dc has more Nan values than  the Electrode positive or negative, and since they r correlated with the eletrode column, we will consider only the electrode column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['AC or DC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Electrode positive or negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to build a prediction model, we should deal with other categorical variables, let's adress the Type of weld column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all the unique values in the 'Type of weld' column\n",
    "df['Type of weld'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoding to 'Type of weld' column\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Type of weld'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the columns names\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore more the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on related articles in the domain of welding and materials science, it is common to handle missing values of certain chemical elements differently. For instance:\n",
    "\n",
    "- Missing values of **Phosphorus (P)** and **Sulphur (S)** are imputed using the **mean values** from the dataset.\n",
    "- Other missing values of other elements such as **Manganese (Mn)**, **Nickel (Ni)**, etc., are set to **0** because these elements are not deliberately added and are likely close to the detection limit of the analytical techniques used.\n",
    "\n",
    "Therefore, we will implement this preprocessing step to ensure that the dataset is correctly handled for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sulphur concentration (weight%)'] = df['Sulphur concentration (weight%)'].fillna(df['Sulphur concentration (weight%)'].mean())\n",
    "df['Phosphorus concentration (weight%)'] = df['Phosphorus concentration (weight%)'].fillna(df['Phosphorus concentration (weight%)'].mean())\n",
    "\n",
    "# Replace missing values for all other concentrations with 0 (as they were not deliberately added)\n",
    "elements_to_zero = ['Manganese concentration (weight%)', 'Sulphur concentration (weight%)',\n",
    "       'Phosphorus concentration (weight%)', 'Nickel concentration (weight%)',\n",
    "       'Chromium concentration (weight%)', 'Molybdenum concentration (weight%)',\n",
    "       'Vanadium concentration (weight%)', 'Copper concentration (weight%)',\n",
    "       'Cobalt concentration (weight%)', 'Tungsten concentration (weight%)',\n",
    "       'Oxygen concentration (ppm)', 'Titanium concentration (ppm)',\n",
    "       'Nitrogen concentration (ppm)', 'Aluminium concentration (ppm)',\n",
    "       'Boron concentration (ppm)', 'Niobium concentration (ppm)',\n",
    "       'Tin concentration (ppm)', 'Arsenic concentration (ppm)',\n",
    "       'Antimony concentration (ppm)']\n",
    "\n",
    "# Replace missing values with 0 for the other elements\n",
    "df[elements_to_zero] = df[elements_to_zero].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification du remplacement des colonnes de tension et d'intensité par une colonne de puissance\n",
    "\n",
    "Les colonnes de **Voltage** (en volts) et d'**Current** (en ampères) ont été remplacées par une colonne unique représentant la **Puissance** (en watts). Ce choix est justifié par la relation physique qui lie ces trois grandeurs, à savoir que la puissance électrique est définie par le produit de la tension et de l'intensité\n",
    "$$\n",
    "P = U \\times I\n",
    "$$\n",
    "\n",
    "L'ajout d'une colonne de puissance permet de capturer l'interaction entre la tension et l'intensité dans une seule variable, ce qui réduit la redondance des données et simplifie l'analyse tout en conservant une information complète. De plus, dans de nombreux cas d'application en modélisation, la puissance est plus représentative du comportement global d'un système électrique que ses composantes individuelles (tension et intensité).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Puissance (W)']=df['Voltage (V)']*df['Current (A)']\n",
    "df['Puissance (W)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Current (A)', 'Voltage (V)', 'Weld ID'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = df.select_dtypes(include='bool').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all boolean columns to integers (0 for False, 1 for True)\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the relevant columns\n",
    "df13 = df[['Yield strength (MPa)', 'Ultimate tensile strength (MPa)']]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr2 = df13.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(corr2, \n",
    "            xticklabels=corr2.columns.values, \n",
    "            yticklabels=corr2.columns.values, \n",
    "            annot=True, cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
