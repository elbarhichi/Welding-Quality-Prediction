{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Reduction of Area (%)'\n",
    "trgt = 'Reduction_of_area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "\n",
    "# Charger la data PCA transformée\n",
    "df = pd.read_csv(f'Transformed data/pca_transformed_dataset_{trgt}.csv')\n",
    "\n",
    "# Séparer les features et la target\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Séparer en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les modèles de régression\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RidgeRegression': Ridge(),\n",
    "    'LassoRegression': Lasso(),\n",
    "    'ElasticNetRegression': ElasticNet(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les grilles de recherche d'hyperparamètres pour GridSearch\n",
    "param_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'RidgeRegression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "    'LassoRegression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "    'ElasticNetRegression': {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [5, 10, 20, None], 'min_samples_split': [2, 10, 20]},\n",
    "    'RandomForestRegressor': {'n_estimators': [100, 200], 'max_depth': [10, 20, None]},\n",
    "    'GradientBoostingRegressor': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 10]},\n",
    "    'SVR': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']} \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les scorers\n",
    "scoring = {\n",
    "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'RMSE': make_scorer(root_mean_squared_error, greater_is_better=False),\n",
    "    'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'R2': 'r2'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la meilleure métrique pour refit dans notre cas ?\n",
    "\n",
    "Pour la prédiction de la Yield strength (MPa), une métrique comme RMSE est souvent utile car elle est directement interprétable en termes de l'unité de la variable cible (MPa), ce qui permet de comprendre facilement l'ampleur des erreurs.\n",
    "\n",
    "RMSE pourrait être un bon choix pour refit, car il permet d'avoir une mesure intuitive de l'erreur moyenne en termes d'unités MPa. Cela facilitera l'interprétation de la performance du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les meilleurs modèles et paramètres\n",
    "best_models = {}\n",
    "\n",
    "# Tableau pour stocker les résultats\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Best Parameters': [],\n",
    "    'Train MSE': [],\n",
    "    'Train RMSE': [],\n",
    "    'Train MAE': [],\n",
    "    'Train R²': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearRegression...\n",
      "Training RidgeRegression...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LassoRegression...\n",
      "Training ElasticNetRegression...\n",
      "Training DecisionTreeRegressor...\n",
      "Training RandomForestRegressor...\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grids[model_name], scoring=scoring, refit='RMSE', cv=5, return_train_score=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Stocker le meilleur modèle\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "    \n",
    "    # Enregistrer les paramètres optimaux\n",
    "    results['Model'].append(model_name)\n",
    "    results['Best Parameters'].append(grid.best_params_)\n",
    "    \n",
    "    # Prédire sur l'ensemble d'entraînement\n",
    "    y_train_pred = grid.predict(X_train)\n",
    "    \n",
    "    # Calculer les métriques pour l'entraînement\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = root_mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    results['Train MSE'].append(train_mse)\n",
    "    results['Train RMSE'].append(train_rmse)\n",
    "    results['Train MAE'].append(train_mae)\n",
    "    results['Train R²'].append(train_r2)\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame des résultats\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder chaque meilleur modèle dans un fichier séparé\n",
    "for model_name, model in best_models.items():\n",
    "    joblib.dump(model, f'Trained model/{model_name}_best_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
